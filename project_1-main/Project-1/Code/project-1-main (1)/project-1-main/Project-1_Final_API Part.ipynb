{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dependencies\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.legend_handler import HandlerLine2D\n",
    "import requests\n",
    "import pandas as pd\n",
    "from config import api_key\n",
    "import json\n",
    "import pandas as pd\n",
    "import glob\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) API: Requests URL & Create CSV File"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### API: American Community Survey 1-Year Data (2005-2019) - State Level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '..\\\\Resources_api\\\\2009_transportation.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-8341f70a8647>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcol_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[0mclean_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'state code'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m     \u001b[0mclean_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf'..\\Resources_api\\{year}_{title}.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36mto_csv\u001b[1;34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, line_terminator, chunksize, date_format, doublequote, escapechar, decimal)\u001b[0m\n\u001b[0;32m   3202\u001b[0m             \u001b[0mdecimal\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdecimal\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3203\u001b[0m         )\n\u001b[1;32m-> 3204\u001b[1;33m         \u001b[0mformatter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3205\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3206\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mpath_or_buf\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\formats\\csvs.py\u001b[0m in \u001b[0;36msave\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    182\u001b[0m             \u001b[0mclose\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    183\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 184\u001b[1;33m             f, handles = get_handle(\n\u001b[0m\u001b[0;32m    185\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath_or_buf\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    186\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\common.py\u001b[0m in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text)\u001b[0m\n\u001b[0;32m    426\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mencoding\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    427\u001b[0m             \u001b[1;31m# Encoding\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 428\u001b[1;33m             \u001b[0mf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath_or_buf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnewline\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    429\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mis_text\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    430\u001b[0m             \u001b[1;31m# No explicit encoding\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '..\\\\Resources_api\\\\2009_transportation.csv'"
     ]
    }
   ],
   "source": [
    "# Create csv file for individual year from 2009 to 2019\n",
    "\n",
    "# Means of Transportation\n",
    "years = ['2009','2010','2011','2012','2013','2014','2015','2016','2017','2018','2019']\n",
    "variable = 'B08101_001E'\n",
    "title = 'transportation'\n",
    "\n",
    "for year in years:\n",
    "    url = f'https://api.census.gov/data/{year}/acs/acs1?get=NAME,{variable}&for=state:*&key={api_key}'\n",
    "    data = requests.get(url).json()\n",
    "    col_name = ['state', year, 'state code']\n",
    "    df = pd.DataFrame(data[1:], columns=col_name)\n",
    "    clean_df = df.drop(columns=['state code'])\n",
    "    clean_df.to_csv(f'..\\Resources_api\\{year}_{title}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Worked From Home\n",
    "years = ['2009','2010','2011','2012','2013','2014','2015','2016','2017','2018','2019']\n",
    "variable = 'B08101_049E'\n",
    "title = 'worked_fm_home'\n",
    "\n",
    "for year in years:\n",
    "    url = f'https://api.census.gov/data/{year}/acs/acs1?get=NAME,{variable}&for=state:*&key={api_key}'\n",
    "    data = requests.get(url).json()\n",
    "    col_name = ['state', year, 'state code']\n",
    "    df = pd.DataFrame(data[1:], columns=col_name)\n",
    "    clean_df = df.drop(columns=['state code'])\n",
    "    clean_df.to_csv(f'{year}_{title}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drove Alone\n",
    "years = ['2009','2010','2011','2012','2013','2014','2015','2016','2017','2018','2019']\n",
    "variable = 'B08101_009E'\n",
    "title = 'drove'\n",
    "\n",
    "for year in years:\n",
    "    url = f'https://api.census.gov/data/{year}/acs/acs1?get=NAME,{variable}&for=state:*&key={api_key}'\n",
    "    data = requests.get(url).json()\n",
    "    col_name = ['state', year, 'state code']\n",
    "    df = pd.DataFrame(data[1:], columns=col_name)\n",
    "    clean_df = df.drop(columns=['state code'])\n",
    "    clean_df.to_csv(f'{year}_{title}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carpooled\n",
    "years = ['2009','2010','2011','2012','2013','2014','2015','2016','2017','2018','2019']\n",
    "variable = 'B08101_017E'\n",
    "title = 'carpooled'\n",
    "\n",
    "for year in years:\n",
    "    url = f'https://api.census.gov/data/{year}/acs/acs1?get=NAME,{variable}&for=state:*&key={api_key}'\n",
    "    data = requests.get(url).json()\n",
    "    col_name = ['state', year, 'state code']\n",
    "    df = pd.DataFrame(data[1:], columns=col_name)\n",
    "    clean_df = df.drop(columns=['state code'])\n",
    "    clean_df.to_csv(f'{year}_{title}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Walked\n",
    "years = ['2009','2010','2011','2012','2013','2014','2015','2016','2017','2018','2019']\n",
    "variable = 'B08101_033E'\n",
    "title = 'walked'\n",
    "\n",
    "for year in years:\n",
    "    url = f'https://api.census.gov/data/{year}/acs/acs1?get=NAME,{variable}&for=state:*&key={api_key}'\n",
    "    data = requests.get(url).json()\n",
    "    col_name = ['state', year, 'state code']\n",
    "    df = pd.DataFrame(data[1:], columns=col_name)\n",
    "    clean_df = df.drop(columns=['state code'])\n",
    "    clean_df.to_csv(f'{year}_{title}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Public Transportation (Excluding Taxi)\n",
    "years = ['2009','2010','2011','2012','2013','2014','2015','2016','2017','2018','2019']\n",
    "variable = 'B08101_025E'\n",
    "title = 'public_transportation'\n",
    "\n",
    "for year in years:\n",
    "    url = f'https://api.census.gov/data/{year}/acs/acs1?get=NAME,{variable}&for=state:*&key={api_key}'\n",
    "    data = requests.get(url).json()\n",
    "    col_name = ['state', year, 'state code']\n",
    "    df = pd.DataFrame(data[1:], columns=col_name)\n",
    "    clean_df = df.drop(columns=['state code'])\n",
    "    clean_df.to_csv(f'{year}_{title}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Taxi, Motercycle, Bicycle\n",
    "years = ['2009','2010','2011','2012','2013','2014','2015','2016','2017','2018','2019']\n",
    "variable = 'B08101_041E'\n",
    "title = 'taxi_bikes'\n",
    "\n",
    "for year in years:\n",
    "    url = f'https://api.census.gov/data/{year}/acs/acs1?get=NAME,{variable}&for=state:*&key={api_key}'\n",
    "    data = requests.get(url).json()\n",
    "    col_name = ['state', year, 'state code']\n",
    "    df = pd.DataFrame(data[1:], columns=col_name)\n",
    "    clean_df = df.drop(columns=['state code'])\n",
    "    clean_df.to_csv(f'{year}_{title}.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) Read CSV Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Toal Means of Transportation\n",
    "df = pd.read_csv('2009_transportation.csv')\n",
    "df_2009 = df.drop(columns=['Unnamed: 0'])\n",
    "\n",
    "df = pd.read_csv('2010_transportation.csv')\n",
    "df_2010 = df.drop(columns=['Unnamed: 0'])\n",
    "\n",
    "df = pd.read_csv('2011_transportation.csv')\n",
    "df_2011 = df.drop(columns=['Unnamed: 0'])\n",
    "\n",
    "df = pd.read_csv('2012_transportation.csv')\n",
    "df_2012 = df.drop(columns=['Unnamed: 0'])\n",
    "\n",
    "df = pd.read_csv('2013_transportation.csv')\n",
    "df_2013 = df.drop(columns=['Unnamed: 0'])\n",
    "\n",
    "df = pd.read_csv('2014_transportation.csv')\n",
    "df_2014 = df.drop(columns=['Unnamed: 0'])\n",
    "\n",
    "df = pd.read_csv('2015_transportation.csv')\n",
    "df_2015 = df.drop(columns=['Unnamed: 0'])\n",
    "\n",
    "df = pd.read_csv('2016_transportation.csv')\n",
    "df_2016 = df.drop(columns=['Unnamed: 0'])\n",
    "\n",
    "df = pd.read_csv('2017_transportation.csv')\n",
    "df_2017 = df.drop(columns=['Unnamed: 0'])\n",
    "\n",
    "df = pd.read_csv('2018_transportation.csv')\n",
    "df_2018 = df.drop(columns=['Unnamed: 0'])\n",
    "\n",
    "df = pd.read_csv('2019_transportation.csv')\n",
    "df_2019 = df.drop(columns=['Unnamed: 0'])\n",
    "\n",
    "dfs = [df.set_index(['state']) for df in [df_2009, df_2010, df_2011, df_2012, df_2013, df_2014, df_2015, df_2016, df_2017, df_2018, df_2019]]\n",
    "transportation_dfs = pd.concat(dfs, axis=1)\n",
    "transportation_df = transportation_dfs.rename(columns={'index':'state'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Worked From Home\n",
    "df = pd.read_csv('2009_worked_fm_home.csv')\n",
    "df_2009 = df.drop(columns=['Unnamed: 0'])\n",
    "\n",
    "df = pd.read_csv('2010_worked_fm_home.csv')\n",
    "df_2010 = df.drop(columns=['Unnamed: 0'])\n",
    "\n",
    "df = pd.read_csv('2011_worked_fm_home.csv')\n",
    "df_2011 = df.drop(columns=['Unnamed: 0'])\n",
    "\n",
    "df = pd.read_csv('2012_worked_fm_home.csv')\n",
    "df_2012 = df.drop(columns=['Unnamed: 0'])\n",
    "\n",
    "df = pd.read_csv('2013_worked_fm_home.csv')\n",
    "df_2013 = df.drop(columns=['Unnamed: 0'])\n",
    "\n",
    "df = pd.read_csv('2014_worked_fm_home.csv')\n",
    "df_2014 = df.drop(columns=['Unnamed: 0'])\n",
    "\n",
    "df = pd.read_csv('2015_worked_fm_home.csv')\n",
    "df_2015 = df.drop(columns=['Unnamed: 0'])\n",
    "\n",
    "df = pd.read_csv('2016_worked_fm_home.csv')\n",
    "df_2016 = df.drop(columns=['Unnamed: 0'])\n",
    "\n",
    "df = pd.read_csv('2017_worked_fm_home.csv')\n",
    "df_2017 = df.drop(columns=['Unnamed: 0'])\n",
    "\n",
    "df = pd.read_csv('2018_worked_fm_home.csv')\n",
    "df_2018 = df.drop(columns=['Unnamed: 0'])\n",
    "\n",
    "df = pd.read_csv('2019_worked_fm_home.csv')\n",
    "df_2019 = df.drop(columns=['Unnamed: 0'])\n",
    "\n",
    "dfs = [df.set_index(['state']) for df in [df_2009, df_2010, df_2011, df_2012, df_2013, df_2014, df_2015, df_2016, df_2017, df_2018, df_2019]]\n",
    "worked_fm_home_dfs = pd.concat(dfs, axis=1)\n",
    "worked_fm_home_df = worked_fm_home_dfs.rename(columns={'index':'state'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drove\n",
    "title = 'drove'\n",
    "\n",
    "df = pd.read_csv(f'2009_{title}.csv')\n",
    "df_2009 = df.drop(columns=['Unnamed: 0'])\n",
    "\n",
    "df = pd.read_csv(f'2010_{title}.csv')\n",
    "df_2010 = df.drop(columns=['Unnamed: 0'])\n",
    "\n",
    "df = pd.read_csv(f'2011_{title}.csv')\n",
    "df_2011 = df.drop(columns=['Unnamed: 0'])\n",
    "\n",
    "df = pd.read_csv(f'2012_{title}.csv')\n",
    "df_2012 = df.drop(columns=['Unnamed: 0'])\n",
    "\n",
    "df = pd.read_csv(f'2013_{title}.csv')\n",
    "df_2013 = df.drop(columns=['Unnamed: 0'])\n",
    "\n",
    "df = pd.read_csv(f'2014_{title}.csv')\n",
    "df_2014 = df.drop(columns=['Unnamed: 0'])\n",
    "\n",
    "df = pd.read_csv(f'2015_{title}.csv')\n",
    "df_2015 = df.drop(columns=['Unnamed: 0'])\n",
    "\n",
    "df = pd.read_csv(f'2016_{title}.csv')\n",
    "df_2016 = df.drop(columns=['Unnamed: 0'])\n",
    "\n",
    "df = pd.read_csv(f'2017_{title}.csv')\n",
    "df_2017 = df.drop(columns=['Unnamed: 0'])\n",
    "\n",
    "df = pd.read_csv(f'2018_{title}.csv')\n",
    "df_2018 = df.drop(columns=['Unnamed: 0'])\n",
    "\n",
    "df = pd.read_csv(f'2019_{title}.csv')\n",
    "df_2019 = df.drop(columns=['Unnamed: 0'])\n",
    "\n",
    "dfs = [df.set_index(['state']) for df in [df_2009, df_2010, df_2011, df_2012, df_2013, df_2014, df_2015, df_2016, df_2017, df_2018, df_2019]]\n",
    "drove_dfs = pd.concat(dfs, axis=1)\n",
    "drove_df = drove_dfs.rename(columns={'index':'state'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carpooled\n",
    "title = 'carpooled'\n",
    "\n",
    "df = pd.read_csv(f'2009_{title}.csv')\n",
    "df_2009 = df.drop(columns=['Unnamed: 0'])\n",
    "\n",
    "df = pd.read_csv(f'2010_{title}.csv')\n",
    "df_2010 = df.drop(columns=['Unnamed: 0'])\n",
    "\n",
    "df = pd.read_csv(f'2011_{title}.csv')\n",
    "df_2011 = df.drop(columns=['Unnamed: 0'])\n",
    "\n",
    "df = pd.read_csv(f'2012_{title}.csv')\n",
    "df_2012 = df.drop(columns=['Unnamed: 0'])\n",
    "\n",
    "df = pd.read_csv(f'2013_{title}.csv')\n",
    "df_2013 = df.drop(columns=['Unnamed: 0'])\n",
    "\n",
    "df = pd.read_csv(f'2014_{title}.csv')\n",
    "df_2014 = df.drop(columns=['Unnamed: 0'])\n",
    "\n",
    "df = pd.read_csv(f'2015_{title}.csv')\n",
    "df_2015 = df.drop(columns=['Unnamed: 0'])\n",
    "\n",
    "df = pd.read_csv(f'2016_{title}.csv')\n",
    "df_2016 = df.drop(columns=['Unnamed: 0'])\n",
    "\n",
    "df = pd.read_csv(f'2017_{title}.csv')\n",
    "df_2017 = df.drop(columns=['Unnamed: 0'])\n",
    "\n",
    "df = pd.read_csv(f'2018_{title}.csv')\n",
    "df_2018 = df.drop(columns=['Unnamed: 0'])\n",
    "\n",
    "df = pd.read_csv(f'2019_{title}.csv')\n",
    "df_2019 = df.drop(columns=['Unnamed: 0'])\n",
    "\n",
    "dfs = [df.set_index(['state']) for df in [df_2009, df_2010, df_2011, df_2012, df_2013, df_2014, df_2015, df_2016, df_2017, df_2018, df_2019]]\n",
    "carpooled_dfs = pd.concat(dfs, axis=1)\n",
    "carpooled_df = carpooled_dfs.rename(columns={'index':'state'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Walked\n",
    "title = 'walked'\n",
    "\n",
    "df = pd.read_csv(f'2009_{title}.csv')\n",
    "df_2009 = df.drop(columns=['Unnamed: 0'])\n",
    "\n",
    "df = pd.read_csv(f'2010_{title}.csv')\n",
    "df_2010 = df.drop(columns=['Unnamed: 0'])\n",
    "\n",
    "df = pd.read_csv(f'2011_{title}.csv')\n",
    "df_2011 = df.drop(columns=['Unnamed: 0'])\n",
    "\n",
    "df = pd.read_csv(f'2012_{title}.csv')\n",
    "df_2012 = df.drop(columns=['Unnamed: 0'])\n",
    "\n",
    "df = pd.read_csv(f'2013_{title}.csv')\n",
    "df_2013 = df.drop(columns=['Unnamed: 0'])\n",
    "\n",
    "df = pd.read_csv(f'2014_{title}.csv')\n",
    "df_2014 = df.drop(columns=['Unnamed: 0'])\n",
    "\n",
    "df = pd.read_csv(f'2015_{title}.csv')\n",
    "df_2015 = df.drop(columns=['Unnamed: 0'])\n",
    "\n",
    "df = pd.read_csv(f'2016_{title}.csv')\n",
    "df_2016 = df.drop(columns=['Unnamed: 0'])\n",
    "\n",
    "df = pd.read_csv(f'2017_{title}.csv')\n",
    "df_2017 = df.drop(columns=['Unnamed: 0'])\n",
    "\n",
    "df = pd.read_csv(f'2018_{title}.csv')\n",
    "df_2018 = df.drop(columns=['Unnamed: 0'])\n",
    "\n",
    "df = pd.read_csv(f'2019_{title}.csv')\n",
    "df_2019 = df.drop(columns=['Unnamed: 0'])\n",
    "\n",
    "dfs = [df.set_index(['state']) for df in [df_2009, df_2010, df_2011, df_2012, df_2013, df_2014, df_2015, df_2016, df_2017, df_2018, df_2019]]\n",
    "walked_dfs = pd.concat(dfs, axis=1)\n",
    "walked_df = walked_dfs.rename(columns={'index':'state'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Public Transportation\n",
    "title = 'public_transportation'\n",
    "\n",
    "df = pd.read_csv(f'2009_{title}.csv')\n",
    "df_2009 = df.drop(columns=['Unnamed: 0'])\n",
    "\n",
    "df = pd.read_csv(f'2010_{title}.csv')\n",
    "df_2010 = df.drop(columns=['Unnamed: 0'])\n",
    "\n",
    "df = pd.read_csv(f'2011_{title}.csv')\n",
    "df_2011 = df.drop(columns=['Unnamed: 0'])\n",
    "\n",
    "df = pd.read_csv(f'2012_{title}.csv')\n",
    "df_2012 = df.drop(columns=['Unnamed: 0'])\n",
    "\n",
    "df = pd.read_csv(f'2013_{title}.csv')\n",
    "df_2013 = df.drop(columns=['Unnamed: 0'])\n",
    "\n",
    "df = pd.read_csv(f'2014_{title}.csv')\n",
    "df_2014 = df.drop(columns=['Unnamed: 0'])\n",
    "\n",
    "df = pd.read_csv(f'2015_{title}.csv')\n",
    "df_2015 = df.drop(columns=['Unnamed: 0'])\n",
    "\n",
    "df = pd.read_csv(f'2016_{title}.csv')\n",
    "df_2016 = df.drop(columns=['Unnamed: 0'])\n",
    "\n",
    "df = pd.read_csv(f'2017_{title}.csv')\n",
    "df_2017 = df.drop(columns=['Unnamed: 0'])\n",
    "\n",
    "df = pd.read_csv(f'2018_{title}.csv')\n",
    "df_2018 = df.drop(columns=['Unnamed: 0'])\n",
    "\n",
    "df = pd.read_csv(f'2019_{title}.csv')\n",
    "df_2019 = df.drop(columns=['Unnamed: 0'])\n",
    "\n",
    "dfs = [df.set_index(['state']) for df in [df_2009, df_2010, df_2011, df_2012, df_2013, df_2014, df_2015, df_2016, df_2017, df_2018, df_2019]]\n",
    "public_transportation_dfs = pd.concat(dfs, axis=1)\n",
    "public_transportation_df = public_transportation_dfs.rename(columns={'index':'state'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Taxi Bikes\n",
    "title = 'taxi_bikes'\n",
    "\n",
    "df = pd.read_csv(f'2009_{title}.csv')\n",
    "df_2009 = df.drop(columns=['Unnamed: 0'])\n",
    "\n",
    "df = pd.read_csv(f'2010_{title}.csv')\n",
    "df_2010 = df.drop(columns=['Unnamed: 0'])\n",
    "\n",
    "df = pd.read_csv(f'2011_{title}.csv')\n",
    "df_2011 = df.drop(columns=['Unnamed: 0'])\n",
    "\n",
    "df = pd.read_csv(f'2012_{title}.csv')\n",
    "df_2012 = df.drop(columns=['Unnamed: 0'])\n",
    "\n",
    "df = pd.read_csv(f'2013_{title}.csv')\n",
    "df_2013 = df.drop(columns=['Unnamed: 0'])\n",
    "\n",
    "df = pd.read_csv(f'2014_{title}.csv')\n",
    "df_2014 = df.drop(columns=['Unnamed: 0'])\n",
    "\n",
    "df = pd.read_csv(f'2015_{title}.csv')\n",
    "df_2015 = df.drop(columns=['Unnamed: 0'])\n",
    "\n",
    "df = pd.read_csv(f'2016_{title}.csv')\n",
    "df_2016 = df.drop(columns=['Unnamed: 0'])\n",
    "\n",
    "df = pd.read_csv(f'2017_{title}.csv')\n",
    "df_2017 = df.drop(columns=['Unnamed: 0'])\n",
    "\n",
    "df = pd.read_csv(f'2018_{title}.csv')\n",
    "df_2018 = df.drop(columns=['Unnamed: 0'])\n",
    "\n",
    "df = pd.read_csv(f'2019_{title}.csv')\n",
    "df_2019 = df.drop(columns=['Unnamed: 0'])\n",
    "\n",
    "dfs = [df.set_index(['state']) for df in [df_2009, df_2010, df_2011, df_2012, df_2013, df_2014, df_2015, df_2016, df_2017, df_2018, df_2019]]\n",
    "taxi_bikes_dfs = pd.concat(dfs, axis=1)\n",
    "taxi_bikes_df = taxi_bikes_dfs.rename(columns={'index':'state'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) Create DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1) DMV Means of Transporation Individual DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DMV Total Means of Transportation\n",
    "#transportation_df\n",
    "va_transportation = pd.DataFrame(transportation_df.loc['Virginia']).rename(columns={'Virginia':'VA Total'})\n",
    "dc_transportation = pd.DataFrame(transportation_df.loc['District of Columbia']).rename(columns={'District of Columbia':'DC Total'})\n",
    "md_transportation = pd.DataFrame(transportation_df.loc['Maryland']).rename(columns={'Maryland':'MD Total'})\n",
    "dmv_total = pd.concat([va_transportation, dc_transportation, md_transportation], axis=1)\n",
    "dmv_total.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DMV Worked From Home\n",
    "# worked_fm_home_df\n",
    "va_worked_fm_home = pd.DataFrame(worked_fm_home_df.loc['Virginia']).rename(columns={'Virginia':'VA fm Home'})\n",
    "dc_worked_fm_home = pd.DataFrame(worked_fm_home_df.loc['District of Columbia']).rename(columns={'District of Columbia':'DC fm Home'})\n",
    "md_worked_fm_home = pd.DataFrame(worked_fm_home_df.loc['Maryland']).rename(columns={'Maryland':'MD fm Home'})\n",
    "dmv_worked_fm_home = pd.concat([va_worked_fm_home, dc_worked_fm_home, md_worked_fm_home], axis=1)\n",
    "dmv_worked_fm_home.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DMV Drove\n",
    "# drove_df\n",
    "va_drove = pd.DataFrame(drove_df.loc['Virginia']).rename(columns={'Virginia':'VA Drove'})\n",
    "dc_drove = pd.DataFrame(drove_df.loc['District of Columbia']).rename(columns={'District of Columbia':'DC Drove'})\n",
    "md_drove = pd.DataFrame(drove_df.loc['Maryland']).rename(columns={'Maryland':'MD Drove'})\n",
    "dmv_drove = pd.concat([va_drove, dc_drove, md_drove], axis=1)\n",
    "dmv_drove.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DMV Carpooled\n",
    "# carpooled_df\n",
    "va_carpooled = pd.DataFrame(carpooled_df.loc['Virginia']).rename(columns={'Virginia':'VA Carpooled'})\n",
    "dc_carpooled = pd.DataFrame(carpooled_df.loc['District of Columbia']).rename(columns={'District of Columbia':'DC Carpooled'})\n",
    "md_carpooled = pd.DataFrame(carpooled_df.loc['Maryland']).rename(columns={'Maryland':'MD Carpooled'})\n",
    "dmv_carpooled = pd.concat([va_carpooled, dc_carpooled, md_carpooled], axis=1)\n",
    "dmv_carpooled.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DMV Walked\n",
    "# walked_df\n",
    "va_walked = pd.DataFrame(walked_df.loc['Virginia']).rename(columns={'Virginia':'VA Walked'})\n",
    "dc_walked = pd.DataFrame(walked_df.loc['District of Columbia']).rename(columns={'District of Columbia':'DC Walked'})\n",
    "md_walked = pd.DataFrame(walked_df.loc['Maryland']).rename(columns={'Maryland':'MD Walked'})\n",
    "dmv_walked = pd.concat([va_walked, dc_walked, md_walked], axis=1)\n",
    "dmv_walked.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DMV Public Transportation\n",
    "# public_transportation_df\n",
    "va_public_transportation = pd.DataFrame(public_transportation_df.loc['Virginia']).rename(columns={'Virginia':'VA Public Transportation'})\n",
    "dc_public_transportation = pd.DataFrame(public_transportation_df.loc['District of Columbia']).rename(columns={'District of Columbia':'DC Public Transportation'})\n",
    "md_public_transportation = pd.DataFrame(public_transportation_df.loc['Maryland']).rename(columns={'Maryland':'MD Public Transportation'})\n",
    "dmv_public_transportation = pd.concat([va_public_transportation, dc_public_transportation, md_public_transportation], axis=1)\n",
    "dmv_public_transportation.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DMV Taxi and Bikes\n",
    "# taxi_bikes_df \n",
    "dmv_taxi_bikes = pd.DataFrame(taxi_bikes_df.loc[['Virginia','District of Columbia','Maryland']])\n",
    "\n",
    "va_taxi_bikes = pd.DataFrame(taxi_bikes_df.loc['Virginia']).rename(columns={'Virginia':'VA Taxi/Bikes'})\n",
    "dc_taxi_bikes = pd.DataFrame(taxi_bikes_df.loc['District of Columbia']).rename(columns={'District of Columbia':'DC Taxi/Bikes'})\n",
    "md_taxi_bikes = pd.DataFrame(taxi_bikes_df.loc['Maryland']).rename(columns={'Maryland':'MD Taxi/Bikes'})\n",
    "dmv_taxi_bikes = pd.concat([va_taxi_bikes, dc_taxi_bikes, md_taxi_bikes], axis=1)\n",
    "dmv_taxi_bikes.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2) DMA Area: Expenditure DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Read SAEXP1__ALL_AREAS_1997_2019.csv\n",
    "file = 'Resources\\SAEXP1__ALL_AREAS_1997_2019.csv'\n",
    "data = pd.read_csv(file)\n",
    "data.head()\n",
    "\n",
    "data2 = data[['GeoName', 'Description','2009','2010','2011','2012','2013','2014','2015','2016','2017','2018','2019']]\n",
    "data3 = data2.set_index('GeoName')\n",
    "\n",
    "# VA, MD, DC\n",
    "va_data = data3.loc['Virginia'].rename(columns={'Description':'VA Description'}).set_index('VA Description')\n",
    "md_data = data3.loc['Maryland'].rename(columns={'Description':'MD Description'}).set_index('MD Description')\n",
    "dc_data = data3.loc['District of Columbia'].rename(columns={'Description':'DC Description'}).set_index('DC Description')\n",
    "\n",
    "# motor_vehicles_and_parts\n",
    "va_motor = pd.DataFrame(va_data.iloc[3])\n",
    "md_motor = pd.DataFrame(md_data.iloc[3])\n",
    "dc_motor = pd.DataFrame(dc_data.iloc[3])\n",
    "\n",
    "# transportation_services \n",
    "va_tservice = pd.DataFrame(va_data.iloc[16])\n",
    "md_tservice = pd.DataFrame(md_data.iloc[16])\n",
    "dc_tservice = pd.DataFrame(dc_data.iloc[16])\n",
    "\n",
    "# Merge: motor_vehicles_and_parts + transportation_services\n",
    "va_motor_tservice = pd.concat([va_motor, va_tservice], axis=1)\n",
    "md_motor_tservice = pd.concat([md_motor, md_tservice], axis=1)\n",
    "dc_motor_tservice = pd.concat([dc_motor, dc_tservice], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4) Plots and Data Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Summaries and Reflecting Questions\n",
    "1. The expenditure on motor vehicles and parts: More in VA than in MD.\n",
    "2. Population that used public transporation to work: More in MD than in VA. \n",
    "\n",
    "\n",
    "#### Reflectiing Question:\n",
    "1. How often do people in VA/MD use public transporation?\n",
    "2. What are the average travelling distance?\n",
    "3. How do frequency and distance affect expenditures in public transportation?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Expenditure and Population Comparison: Public Transporation Service (VA/MD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Public Transporation\n",
    "year = ['2009','2010','2011','2012','2013','2014','2015','2016','2017','2018','2019']\n",
    "# Population\n",
    "va_public_transportation = dmv_public_transportation['VA Public Transportation']\n",
    "md_public_transportation = dmv_public_transportation['MD Public Transportation']\n",
    "\n",
    "# Expenditure\n",
    "va_tservice = pd.DataFrame(va_data.iloc[16])\n",
    "md_tservice = pd.DataFrame(md_data.iloc[16])\n",
    "\n",
    "# Plot\n",
    "fig, (ax1, ax2) = plt.subplots(nrows=1, ncols=2)\n",
    "ax1.plot(year, va_public_transportation, color = 'coral', linestyle = '--', label='VA')\n",
    "ax1.plot(year, md_public_transportation, color = 'steelblue', linestyle = '--', label='MD')\n",
    "\n",
    "ax2.plot(year, va_tservice, color = 'coral', label='VA')\n",
    "ax2.plot(year, md_tservice, color = 'steelblue', label='MD')\n",
    "\n",
    "ax1.legend()\n",
    "ax1.set_title('Population: PTS')\n",
    "ax1.set_ylabel('Population')\n",
    "\n",
    "ax2.legend()\n",
    "ax2.set_title('Expenditure: PTS')\n",
    "ax2.set_ylabel('Millions of Dollars')\n",
    "\n",
    "plt.setp((ax1, ax2), xticks=[0, 5, 10], xticklabels=['2009', '2015', '2019'])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "fig.savefig('Public Transportation.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dmv_carpooled\n",
    "#dmv_carpooled.sum()\n",
    "dmv_public_transportation\n",
    "#dmv_public_transportation.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 3: ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#locating the csv files...\n",
    "#year 2009-2019...\n",
    "carpooled_csv = \"Resources/carpool.csv\"\n",
    "drove_csv = \"Resources/drove.csv\"\n",
    "publicTrans_csv = \"Resources/publicTransit.csv\"\n",
    "taxiBikes_csv = \"Resources/taxiBikes.csv\"\n",
    "transport_csv = \"Resources/transportation.csv\"\n",
    "walk_csv = \"Resources/walked.csv\"\n",
    "wfh_csv = \"Resources/wfh.csv\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reading the csv files...\n",
    "\n",
    "#year 2009-2019...\n",
    "carpooled_df = pd.read_csv(carpooled_csv)\n",
    "drove_df = pd.read_csv(drove_csv)\n",
    "publicTrans_df = pd.read_csv(publicTrans_csv)\n",
    "taxiBikes_df = pd.read_csv(taxiBikes_csv)\n",
    "transport_df = pd.read_csv(transport_csv)\n",
    "walk_df = pd.read_csv(walk_csv)\n",
    "wfh_df = pd.read_csv(wfh_csv)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the first two datasets on \"state\" so that no data is lost\n",
    "combined_states_df = pd.merge(carpooled_df, drove_df, how='outer', on='state')\n",
    "combined_states_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename our _x columns to \"carpool2009\", \"carpool2010\", \"carpool2011\", ...\"carpool2019\"\n",
    "combined_states_df = combined_states_df.rename(columns={\"2009_x\":\"carpool2009\", \"2010_x\":\"carpool2010\",\"2011_x\":\"carpool2011\", \"2012_x\":\"carpool2012\",\"2013_x\":\"carpool2013\",\"2014_x\":\"carpool2014\", \"2015_x\":\"carpool2015\",\"2016_x\":\"carpool2016\",\"2017_x\":\"carpool2017\", \"2018_x\":\"carpool2018\",\"2019_x\":\"carpool2019\"})\n",
    "\n",
    "# Rename our _y columns to \"drove2009\", \"drove2010\", \"drove2011\", ...\"drove2019\"\n",
    "combined_states_df = combined_states_df.rename(columns={\"2009_y\":\"drove2009\",\"2010_y\":\"drove2010\",\"2011_y\":\"drove2011\", \"2012_y\":\"drove2012\",\"2013_y\":\"drove2013\",\"2014_y\":\"drove2014\", \"2015_y\":\"drove2015\",\"2016_y\":\"drove2016\",\"2017_y\":\"drove2017\", \"2018_y\":\"drove2018\",\"2019_y\":\"drove2019\"})\n",
    "\n",
    "combined_states_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge our newly combined dataframe with the publicTrans_df dataframe\n",
    "combined_states_df = pd.merge(combined_states_df, publicTrans_df, how=\"outer\", on=\"state\")\n",
    "combined_states_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename \"2009\", \"2010\", ... \"2019\" to \"public2009\", \"public2010\", ...\"public2019\"\n",
    "combined_states_df = combined_states_df.rename(columns={\"2009\":\"public2009\",\"2010\":\"public2010\",\"2011\":\"public2011\", \"2012\":\"public2012\",\"2013\":\"public2013\",\"2014\":\"public2014\", \"2015\":\"public2015\",\"2016\":\"public2016\",\"2017\":\"public2017\", \"2018\":\"public2018\",\"2019\":\"public2019\"})\n",
    "\n",
    "combined_states_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge our newly combined dataframe with the taxiBikes_df dataframe\n",
    "combined_states_df = pd.merge(combined_states_df, taxiBikes_df, how=\"outer\", on=\"state\")\n",
    "combined_states_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename \"2009\", \"2010\", ... \"2019\" to \"taxi2009\", \"taxi2010\", ...\"taxi2019\"\n",
    "combined_states_df = combined_states_df.rename(columns={\"2009\":\"taxi2009\",\"2010\":\"taxi2010\",\"2011\":\"taxi2011\", \"2012\":\"taxi2012\",\"2013\":\"taxi2013\",\"2014\":\"taxi2014\", \"2015\":\"taxi2015\",\"2016\":\"taxi2016\",\"2017\":\"taxi2017\", \"2018\":\"taxi2018\",\"2019\":\"taxi2019\"})\n",
    "\n",
    "combined_states_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge our newly combined dataframe with the transport_df dataframe\n",
    "combined_states_df = pd.merge(combined_states_df, transport_df, how=\"outer\", on=\"state\")\n",
    "combined_states_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename \"2009\", \"2010\", ... \"2019\" to \"transport2009\", \"transport2010\", ...\"transport2019\"\n",
    "combined_states_df = combined_states_df.rename(columns={\"2009\":\"transport2009\",\"2010\":\"transport2010\",\"2011\":\"transport2011\", \"2012\":\"transport2012\",\"2013\":\"transport2013\",\"2014\":\"transport2014\", \"2015\":\"transport2015\",\"2016\":\"transport2016\",\"2017\":\"transport2017\", \"2018\":\"transport2018\",\"2019\":\"transport2019\"})\n",
    "\n",
    "#combined_states_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge our newly combined dataframe with the walk_df dataframe\n",
    "combined_states_df = pd.merge(combined_states_df, walk_df, how=\"outer\", on=\"state\")\n",
    "#combined_states_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename \"2009\", \"2010\", ... \"2019\" to \"walk2009\", \"walk2010\", ...\"walk2019\"\n",
    "combined_states_df = combined_states_df.rename(columns={\"2009\":\"walk2009\",\"2010\":\"walk2010\",\"2011\":\"walk2011\", \"2012\":\"walk2012\",\"2013\":\"walk2013\",\"2014\":\"walk2014\", \"2015\":\"walk2015\",\"2016\":\"walk2016\",\"2017\":\"walk2017\", \"2018\":\"walk2018\",\"2019\":\"walk2019\"})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge our newly combined dataframe with the wfh_df dataframe\n",
    "combined_states_df = pd.merge(combined_states_df, wfh_df, how=\"outer\", on=\"state\")\n",
    "#combined_states_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename \"2009\", \"2010\", ... \"2019\" to \"WFH2009\", \"WFH2010\", ...\"WFH2019\"\n",
    "combined_states_df = combined_states_df.rename(columns={\"2009\":\"WFH2009\",\"2010\":\"WFH2010\",\"2011\":\"WFH2011\", \"2012\":\"WFH2012\",\"2013\":\"WFH2013\",\"2014\":\"WFH2014\", \"2015\":\"WFH2015\",\"2016\":\"WFH2016\",\"2017\":\"WFH2017\", \"2018\":\"WFH2018\",\"2019\":\"WFH2019\"})\n",
    "\n",
    "combined_states_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace all NaN values with 0 \n",
    "combined_states_df = combined_states_df.fillna(0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new column called \"Total Carpool\" and add up each state's numbers per year to fill in the values\n",
    "combined_states_df[\"Total Carpool\"] = combined_states_df[\"carpool2009\"] + combined_states_df[\"carpool2010\"] + combined_states_df[\"carpool2011\"] + combined_states_df[\"carpool2012\"] + combined_states_df[\"carpool2013\"] + combined_states_df[\"carpool2014\"] + combined_states_df[\"carpool2015\"] + combined_states_df[\"carpool2016\"] + combined_states_df[\"carpool2017\"] + combined_states_df[\"carpool2018\"] + combined_states_df[\"carpool2019\"]\n",
    "\n",
    "# Create a new column called \"Total Drove\" and add up each state's numbers per year to fill in the values\n",
    "combined_states_df[\"Total Drove\"] = combined_states_df[\"drove2009\"] + combined_states_df[\"drove2010\"] + combined_states_df[\"drove2011\"] + combined_states_df[\"drove2012\"] + combined_states_df[\"drove2013\"] + combined_states_df[\"drove2014\"] + combined_states_df[\"drove2015\"] + combined_states_df[\"drove2016\"] + combined_states_df[\"drove2017\"] + combined_states_df[\"drove2018\"] + combined_states_df[\"drove2019\"]\n",
    "\n",
    "# Create a new column called \"Total PublicTransit\" and add up each state's numbers per year to fill in the values\n",
    "combined_states_df[\"Total PublicTransit\"] = combined_states_df[\"public2009\"] + combined_states_df[\"public2010\"] + combined_states_df[\"public2011\"] + combined_states_df[\"public2012\"] + combined_states_df[\"public2013\"] + combined_states_df[\"public2014\"] + combined_states_df[\"public2015\"] + combined_states_df[\"public2016\"] + combined_states_df[\"public2017\"] + combined_states_df[\"public2018\"] + combined_states_df[\"public2019\"]\n",
    "\n",
    "# Create a new column called \"Total taxiBikes\" and add up each state's numbers per year to fill in the values\n",
    "combined_states_df[\"Total TaxiBikes\"] = combined_states_df[\"taxi2009\"] + combined_states_df[\"taxi2010\"] + combined_states_df[\"taxi2011\"] + combined_states_df[\"taxi2012\"] + combined_states_df[\"taxi2013\"] + combined_states_df[\"taxi2014\"] + combined_states_df[\"taxi2015\"] + combined_states_df[\"taxi2016\"] + combined_states_df[\"taxi2017\"] + combined_states_df[\"taxi2018\"] + combined_states_df[\"taxi2019\"]\n",
    "\n",
    "# Create a new column called \"Total Transport\" and add up each state's numbers per year to fill in the values\n",
    "combined_states_df[\"Total Transport\"] = combined_states_df[\"transport2009\"] + combined_states_df[\"transport2010\"] + combined_states_df[\"transport2011\"] + combined_states_df[\"transport2012\"] + combined_states_df[\"transport2013\"] + combined_states_df[\"transport2014\"] + combined_states_df[\"transport2015\"] + combined_states_df[\"transport2016\"] + combined_states_df[\"transport2017\"] + combined_states_df[\"transport2018\"] + combined_states_df[\"transport2019\"]\n",
    "\n",
    "# Create a new column called \"Total Walked\" and add up each state's numbers per year to fill in the values\n",
    "combined_states_df[\"Total Walked\"] = combined_states_df[\"walk2009\"] + combined_states_df[\"walk2010\"] + combined_states_df[\"walk2011\"] + combined_states_df[\"walk2012\"] + combined_states_df[\"walk2013\"] + combined_states_df[\"walk2014\"] + combined_states_df[\"walk2015\"] + combined_states_df[\"walk2016\"] + combined_states_df[\"walk2017\"] + combined_states_df[\"walk2018\"] + combined_states_df[\"walk2019\"]\n",
    "\n",
    "# Create a new column called \"Total WFH\" and add up each state's numbers per year to fill in the values\n",
    "combined_states_df[\"Total WFH\"] = combined_states_df[\"WFH2009\"] + combined_states_df[\"WFH2010\"] + combined_states_df[\"WFH2011\"] + combined_states_df[\"WFH2012\"] + combined_states_df[\"WFH2013\"] + combined_states_df[\"WFH2014\"] + combined_states_df[\"WFH2015\"] + combined_states_df[\"WFH2016\"] + combined_states_df[\"WFH2017\"] + combined_states_df[\"WFH2018\"] + combined_states_df[\"WFH2019\"]\n",
    "\n",
    "\n",
    "# Create a new column called \"Grand Total\" and add up the total Carpool, Drove, PublicTransit, TaxiBikes, Transport, Walked, and WFH for each state to fill in the values\n",
    "combined_states_df[\"Grand Total\"] = combined_states_df[\"Total Carpool\"] + combined_states_df[\"Total Drove\"] + combined_states_df[\"Total PublicTransit\"] + combined_states_df[\"Total TaxiBikes\"] + combined_states_df[\"Total Transport\"] + combined_states_df[\"Total Walked\"] + combined_states_df[\"Total WFH\"]\n",
    "\n",
    "combined_states_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new dataframe for those states who have a population of at least five million...\n",
    "# have at least 500k in Total driving & total Public transit.\n",
    "\n",
    "states_over_5million = combined_states_df.loc[(combined_states_df[\"Grand Total\"] >= 5000000)]\n",
    "\n",
    "# Set the index of this new dataframe to be the state's names\n",
    "states_over_5million = states_over_5million.set_index(\"state\")\n",
    "\n",
    "#states_over_5million"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Charting transport population...\n",
    "\n",
    "* Create a variable and an input that asks the user what State they would like to look for.\n",
    "\n",
    "* Store each individual State's output over time in a variable\n",
    "\n",
    "* Store that same State's output over time in a variable as well\n",
    "\n",
    "* Create a line chart that will plot this States's output and output from 2009 to 2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect the user's input to search through our data frame\n",
    "state_1 = \"Virginia\" # input(\"Type the first state you want to compare? \")\n",
    "state_2 = \"Maryland\" #input(\"Type the first state you want to compare? \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "states_over_5million.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a series that looks for a State by name and then traces their Carpool population from 2009 to 2019\n",
    "carpool_over_time1 = states_over_5million.loc[state_1,[\"carpool2009\",\"carpool2010\", \"carpool2011\", \"carpool2012\", \"carpool2013\",\n",
    "                                                        \"carpool2014\", \"carpool2015\", \"carpool2016\", \"carpool2017\", \"carpool2018\", \"carpool2019\"]]\n",
    "\n",
    "# Create a series that looks for a State by name and then traces their Public population from 2009 to 2019\n",
    "publicTransit_over_time1 = states_over_5million.loc[state_1,[\"public2009\",\"public2010\", \"public2011\", \"public2012\", \"public2013\",\n",
    "                                                       \"public2014\", \"public2015\", \"public2016\", \"public2017\", \"public2018\", \"public2019\"]]\n",
    "\n",
    "\n",
    "# Create a series that looks for a State by name and then traces their Carpool population from 2009 to 2019\n",
    "carpool_over_time2 = states_over_5million.loc[state_2,[\"carpool2009\",\"carpool2010\", \"carpool2011\", \"carpool2012\", \"carpool2013\",\n",
    "                                                        \"carpool2014\", \"carpool2015\", \"carpool2016\", \"carpool2017\", \"carpool2018\", \"carpool2019\"]]\n",
    "\n",
    "# Create a series that looks for a State by name and then traces their Public population from 2009 to 2019\n",
    "publicTransit_over_time2 = states_over_5million.loc[state_2,[\"public2009\",\"public2010\", \"public2011\", \"public2012\", \"public2013\",\n",
    "                                                        \"public2014\", \"public2015\", \"public2016\", \"public2017\", \"public2018\", \"public2019\"]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of the years that we will use as our x axis\n",
    "years = [2009,2010,2011,2012,2013,2014,2015,2016,2017,2018,2019]\n",
    "plt.figure()\n",
    "# Plot our line that will be used to track a States's Carpool over the years...\n",
    "plt.plot(years, publicTransit_over_time1, color=\"mediumvioletred\", linestyle = '--', label=f\"{state_1}'s Public\")\n",
    "plt.plot(years, publicTransit_over_time2, color=\"aqua\", linestyle = '--', label=f\"{state_2}'s Public\")\n",
    "\n",
    "# Plot our line that will be used to track a State's Driving over the years...\n",
    "plt.plot(years, carpool_over_time1, color=\"crimson\", label=f\"{state_1}'s Carpool\")\n",
    "plt.plot(years, carpool_over_time2, color=\"blue\", label=f\"{state_2}'s Carpool\")\n",
    "\n",
    "# Place a legend on the chart in what matplotlib believes to be the \"best\" location\n",
    "plt.legend(bbox_to_anchor=(0.5, 0., 0.5, 0.5), loc='center', borderaxespad=0.1)\n",
    "\n",
    "\n",
    "\n",
    "plt.title(state_1 +  ' '+ 'vs' + ' ' + state_2 + \"'s Transport Population\") \n",
    "plt.xlabel(\"Years\")\n",
    "plt.xticks(np.arange(min(years), max(years)+1, 1.0))\n",
    "plt.ylabel(\"Number of Carpool/Public Transport\")\n",
    "\n",
    "# Print our chart to the screen\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
